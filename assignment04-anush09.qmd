---
title: Assignment 04
author:
  - name: Anu Sharma
    affiliations:
      - id: anush09
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-10-03'
date-modified: today
date-format: long
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2

execute:
  echo: false
  eval: false
  freeze: auto
---

## Github URL
https://github.com/met-ad-688/assignment-04-anush-09.git


```{python}
#| eval: true
#| echo: true
#| output: true
from pyspark.sql import SparkSession
import pandas as pd
import plotly.express as px
import plotly.io as pio
import numpy as np

np.random.seed(42)

pio.renderers.default = "notebook+notebook_connected+vscode"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("./data/lightcast_job_postings.csv")

# # Show Schema and Sample Data
# print("---This is Diagnostic check, No need to print it in the final doc---")

# # df.printSchema() # comment this line when rendering the submission
# df.show(5)
```

## Feature Engineering
```{python}
#| eval: true
#| echo: true
#| output: true

from pyspark.sql.functions import col, pow
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.regression import GeneralizedLinearRegression

# Drop missing values
key_features = [
    "DURATION", "SALARY_FROM", "SALARY_TO", "MIN_YEARS_EXPERIENCE",
    "EMPLOYMENT_TYPE_NAME", "STATE_NAME", "SALARY"
]
df_clean = df.dropna(subset=key_features)

# Categorical transformations
cat_cols = ["EMPLOYMENT_TYPE_NAME", "STATE_NAME"]
indexers = [StringIndexer(inputCol=c, outputCol=c+"_IDX", handleInvalid="keep") for c in cat_cols]
encoders = [OneHotEncoder(inputCol=c+"_IDX", outputCol=c+"_OHE", dropLast=True) for c in cat_cols]

#  Assemble features
cont_cols = ["DURATION", "SALARY_FROM", "SALARY_TO", "MIN_YEARS_EXPERIENCE"]
assembler_inputs = cont_cols + [c+"_OHE" for c in cat_cols]

assembler = VectorAssembler(
    inputCols=assembler_inputs,
    outputCol="features"
)

pipeline = Pipeline(stages=indexers + encoders + [assembler])
df_transformed = pipeline.fit(df_clean).transform(df_clean)

# Train-test split (80/20)
train_df, test_df = df_transformed.randomSplit([0.8, 0.2], seed=42)
# 80% for training and 20% for testing to ensure enough data for model training and validation.

# Create polynomial feature ( by squaring MIN_YEARS_EXPERIENCE)
df_poly = df_transformed.withColumn(
    "MIN_YEARS_EXPERIENCE_SQ", pow(col("MIN_YEARS_EXPERIENCE"), 2)
)

# Assemble polynomial features into new vector
poly_assembler = VectorAssembler(
    inputCols=["features", "MIN_YEARS_EXPERIENCE_SQ"],
    outputCol="features_poly"
)
df_final = poly_assembler.transform(df_poly)
df_final.show(5)
```

##  Generalized Linear Regression model
```{python}
#| eval: true
#| echo: true
#| output: true
lr = GeneralizedLinearRegression(
    family="gaussian",
    link="identity",
    featuresCol="features",
    labelCol="SALARY",
    maxIter=10,
    regParam=0.3
)

lr_model = lr.fit(train_df)

from pyspark.ml.evaluation import RegressionEvaluator
lr_predictions = lr_model.transform(test_df)
evaluator = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction")

print("Coefficients:", lr_model.coefficients)
print("Intercept:", lr_model.intercept)
print("R²:", evaluator.setMetricName("r2").evaluate(lr_predictions))
print("RMSE:", evaluator.setMetricName("rmse").evaluate(lr_predictions))
print("MAE:", evaluator.setMetricName("mae").evaluate(lr_predictions))

# Coefficient statistics
training_summary = lr_model.summary

try:
    coefs = lr_model.coefficients.toArray().tolist()
    se = training_summary.coefficientStandardErrors
    tvals = training_summary.tValues
    pvals = training_summary.pValues

    coef_df = spark.createDataFrame(
        [
            (float(coefs[i]), float(se[i]), float(tvals[i]), float(pvals[i]),
             float(coefs[i] - 1.96*se[i]), float(coefs[i] + 1.96*se[i]))
            for i in range(len(coefs))
        ],
        ["Coefficient", "StdError", "tValue", "pValue", "CI_lower", "CI_upper"]
    )

    coef_df.show(truncate=False)

except Exception as e:
    print("Coefficient statistics not available (L-BGFS fallback):", str(e))
# df_final.printSchema()
```
### Inference
The Generalized Linear Regression model gave very high accuracy (R² ≈ 0.9991), explaining almost all variation in salaries. Prediction errors were very small (RMSE ≈ 1269, MAE ≈ 439). As expected, more years of experience are linked with higher pay, and job type and location also matter.
Looking at coefficients, some predictors (like the second and third features) are highly significant with very low p‑values, while many others have large standard errors and are not statistically meaningful. This shows the presence of multicollinearity: several features are strongly correlated, so the model predicts well overall but individual coefficient estimates are unstable.


##  Polynomial Regression model
```{python}
#| eval: true
#| echo: true
#| output: true

from pyspark.ml.regression import GeneralizedLinearRegression

# train/test
train_poly, test_poly = df_final.randomSplit([0.8, 0.2], seed=42)

# Linear Regression model using polynomial features
lr_poly = GeneralizedLinearRegression(
    family="gaussian",
    link="identity",
    featuresCol="features_poly",
    labelCol="SALARY",
    maxIter=10,
    regParam=0.3
)

#  Fit model on training data
lr_poly_model = lr_poly.fit(train_poly)

from pyspark.ml.evaluation import RegressionEvaluator
poly_predictions = lr_poly_model.transform(test_poly)
evaluator = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction")

print("Polynomial Regression Results")
print("Coefficients:", lr_poly_model.coefficients)
print("Intercept:", lr_poly_model.intercept)
print("R²:", evaluator.setMetricName("r2").evaluate(poly_predictions))
print("RMSE:", evaluator.setMetricName("rmse").evaluate(poly_predictions))
print("MAE:", evaluator.setMetricName("mae").evaluate(poly_predictions))

# Coefficient statistics
poly_summary = lr_poly_model.summary

try:
    coefs = lr_poly_model.coefficients.toArray().tolist()
    se = poly_summary.coefficientStandardErrors
    tvals = poly_summary.tValues
    pvals = poly_summary.pValues

    coef_poly_df = spark.createDataFrame(
        [
            (float(coefs[i]), float(se[i]), float(tvals[i]), float(pvals[i]),
             float(coefs[i] - 1.96*se[i]), float(coefs[i] + 1.96*se[i]))
            for i in range(len(coefs))
        ],
        ["Coefficient", "StdError", "tValue", "pValue", "CI_lower", "CI_upper"]
    )

    coef_poly_df.show(truncate=False)

except Exception as e:
    print("Coefficient statistics not available (L-BGFS fallback):", str(e))
```
### Inference
The Polynomial Regression model also achieved very high accuracy (R² ≈ 0.9991), explaining nearly all variation in salaries. Errors were very small (RMSE ≈ 1269, MAE ≈ 439), almost the same as the linear model. The results again confirm that experience, job type, and location strongly influence pay.
Looking at coefficients, a few predictors (like the second and third features) are highly significant with very low p‑values, but many others show very large standard errors and are not statistically reliable. This again points to multicollinearity: several features overlap in information, so while the model predicts salaries very well, the individual coefficient estimates remain unstable


## Random Forest Regression

```{python}
#| eval: true
#| echo: true
#| output: true

from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator

# Train-test split
train_rf, test_rf = df_transformed.randomSplit([0.8, 0.2], seed=42)

# Random Forest Regression
rf = RandomForestRegressor(
    featuresCol="features",
    labelCol="SALARY",
    numTrees=200,
    maxDepth=6,
    seed=42
)

# Model
rf_model = rf.fit(train_rf)

# Evaluation
rf_predictions = rf_model.transform(test_rf)

evaluator = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction")

r2 = evaluator.setMetricName("r2").evaluate(rf_predictions)
rmse = evaluator.setMetricName("rmse").evaluate(rf_predictions)
mae = evaluator.setMetricName("mae").evaluate(rf_predictions)

print("Random Forest Results")
print("R²:", r2)
print("RMSE:", rmse)
print("MAE:", mae)
```

### Feature Importance Plot

```{python}
#| eval: true
#| echo: true
#| output: true

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# OHE vector size
ohe_sizes = {c+"_OHE": df_transformed.select(c+"_OHE").head()[0].size for c in cat_cols}

# Expanded feature names
expanded_feature_names = []
for col in cont_cols:
    expanded_feature_names.append(col)

for c in cat_cols:
    for i in range(ohe_sizes[c+"_OHE"]):
        expanded_feature_names.append(f"{c}_{i}")

importances = rf_model.featureImportances.toArray()

feat_imp = pd.DataFrame({
    "feature": expanded_feature_names,
    "importance": importances
})

# Top 10 plot
top10 = feat_imp.sort_values("importance", ascending=False).head(10)

plt.figure(figsize=(10,6))
sns.barplot(x="importance", y="feature", data=top10, palette="viridis")
plt.title("Top 10 Feature Importances - Random Forest")
plt.tight_layout()
plt.savefig("_output/rf_feature_importance.png")
plt.show()
plt.close()
```
### Inference
The Random Forest model explained about 97% of salary variation (R² ≈ 0.97). But its errors were higher (RMSE ≈ 7023, MAE ≈ 4381) compared to linear models. From feature importance, we see that SALARY_TO and SALARY_FROM are the main drivers, with years of experience adding some effect. Other features like job type and state have very small impact. This means the model predicts well, but it mostly depends on salary range fields and gives less extra insight.


## Model Comparison

```{python}
#| eval: true
#| echo: true
#| output: true

import pandas as pd
import numpy as np
from pyspark.ml.evaluation import RegressionEvaluator

# Predictions for all three models
lr_predictions = lr_model.transform(test_df)
poly_predictions = lr_poly_model.transform(test_poly)
rf_predictions = rf_model.transform(test_rf)

evaluator = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction")

# Linear Regression metrics
lr_r2 = evaluator.setMetricName("r2").evaluate(lr_predictions)
lr_rmse = evaluator.setMetricName("rmse").evaluate(lr_predictions)
lr_mae = evaluator.setMetricName("mae").evaluate(lr_predictions)

# AIC for Linear Regression
lr_aic = lr_model.summary.aic
print(f"Linear Regression AIC: {lr_aic}")

# Polynomial Regression metrics
poly_r2 = evaluator.setMetricName("r2").evaluate(poly_predictions)
poly_rmse = evaluator.setMetricName("rmse").evaluate(poly_predictions)
poly_mae = evaluator.setMetricName("mae").evaluate(poly_predictions)

# AIC for Polynomial Regression
poly_aic = lr_poly_model.summary.aic
print(f"Polynomial Regression AIC: {poly_aic}")

# AIC is not directly available for Random Forest
rf_aic = None

# BIC calculation for Linear and Polynomial models
def calculate_bic(model_summary, n_obs):
    """Calculate BIC for PySpark GeneralizedLinearRegression models"""
    try:
        k = len(model_summary.coefficientStandardErrors) + 1
        deviance = model_summary.deviance
        dispersion = model_summary.dispersion

        # Log Likelihood calculation
        log_likelihood = -0.5 * (n_obs * np.log(2 * np.pi) + n_obs * np.log(dispersion) + deviance/dispersion)

        # BIC calculation
        bic = k * np.log(n_obs) - 2 * log_likelihood
        return bic
    except Exception as e:
        print(f"BIC calculation failed: {str(e)}")
        return None

n_obs = test_df.count()

lr_bic = calculate_bic(lr_model.summary, n_obs)
poly_bic = calculate_bic(lr_poly_model.summary, n_obs)

print(f"Linear Regression BIC: {lr_bic}")
print(f"Polynomial Regression BIC: {poly_bic}")

comparison_data = {
    'Model': ['Generalized Linear Regression', 'Polynomial Regression', 'Random Forest'],
    'R²': [lr_r2, poly_r2, r2],
    'RMSE': [lr_rmse, poly_rmse, rmse],
    'MAE': [lr_mae, poly_mae, mae],
    'AIC': [lr_aic, poly_aic, 'N/A'],
    'BIC': [lr_bic, poly_bic, 'N/A']
}

comparison_df = pd.DataFrame(comparison_data)
print("Model Comparison:")
print(comparison_df.to_string(index=False))
```

### Visualization Comparison

```{python}
#| eval: true
#| echo: true
#| output: true
import matplotlib.pyplot as plt
import seaborn as sns

lr_pd = lr_predictions.select("SALARY", "prediction").toPandas()
poly_pd = poly_predictions.select("SALARY", "prediction").toPandas()
rf_pd = rf_predictions.select("SALARY", "prediction").toPandas()

fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('Model Predictions vs Actual Values', fontsize=16)

# Generalized Linear Regression
axes[0, 0].scatter(lr_pd['SALARY'], lr_pd['prediction'], alpha=0.6, color='blue')
axes[0, 0].plot([lr_pd['SALARY'].min(), lr_pd['SALARY'].max()],
                [lr_pd['SALARY'].min(), lr_pd['SALARY'].max()], 'r--', lw=2)
axes[0, 0].set_xlabel('Actual Salary')
axes[0, 0].set_ylabel('Predicted Salary')
axes[0, 0].set_title(f'Linear Regression (R² = {lr_r2:.3f})')
axes[0, 0].grid(True, alpha=0.3)

# Polynomial Regression
axes[0, 1].scatter(poly_pd['SALARY'], poly_pd['prediction'], alpha=0.6, color='green')
axes[0, 1].plot([poly_pd['SALARY'].min(), poly_pd['SALARY'].max()],
                [poly_pd['SALARY'].min(), poly_pd['SALARY'].max()], 'r--', lw=2)
axes[0, 1].set_xlabel('Actual Salary')
axes[0, 1].set_ylabel('Predicted Salary')
axes[0, 1].set_title(f'Polynomial Regression (R² = {poly_r2:.3f})')
axes[0, 1].grid(True, alpha=0.3)

# Random Forest
axes[1, 0].scatter(rf_pd['SALARY'], rf_pd['prediction'], alpha=0.6, color='orange')
axes[1, 0].plot([rf_pd['SALARY'].min(), rf_pd['SALARY'].max()],
                [rf_pd['SALARY'].min(), rf_pd['SALARY'].max()], 'r--', lw=2)
axes[1, 0].set_xlabel('Actual Salary')
axes[1, 0].set_ylabel('Predicted Salary')
axes[1, 0].set_title(f'Random Forest (R² = {r2:.3f})')
axes[1, 0].grid(True, alpha=0.3)

# Model comparison bar chart using Seaborn
model_names = ['Linear', 'Polynomial', 'Random Forest']
r2_scores = [lr_r2, poly_r2, r2]
colors = ['blue', 'green', 'orange']
comparison_plot_df = pd.DataFrame({
    'Model': model_names,
    'R²': r2_scores
})

sns.barplot(data=comparison_plot_df, x='R²', y='Model', palette=colors, ax=axes[1, 1])
axes[1, 1].set_xlabel('R² Score')
axes[1, 1].set_title('Model Performance Comparison (R²)')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig("_output/model_comparison.png", dpi=300, bbox_inches='tight')
plt.show()
plt.close()
```

### Inference
Both the Generalized Linear Regression and Polynomial Regression models performed almost identically, with R² ≈ 0.9991 and very low errors (RMSE ≈ 1269, MAE ≈ 439). Their AIC and BIC values are also very close, showing no real advantage of adding polynomial terms.
The Random Forest model explained less variation (R² ≈ 0.97) and had much higher errors (RMSE ≈ 7023, MAE ≈ 4381). Since AIC and BIC are not available for Random Forest, comparison is based only on accuracy metrics.
Overall, the linear models clearly outperform Random Forest for this dataset. Between them, the simpler Generalized Linear Regression is preferable, as it achieves the same accuracy with lower complexity and easier interpretation.
